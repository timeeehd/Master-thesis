{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd59662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3513c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\").cuda()\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# model.load_state_dict(torch.load('models/GPT2-med-2048-512/GPT2-med-2048-512.pt'))\n",
    "\n",
    "# model = GPTNeoForCausalLM.from_pretrained(\"models/GPT-neo\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f9f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test (5).wp_source', \"r\", encoding='utf-8-sig') as file:\n",
    "    data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edeabd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [38:37<00:00,  7.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "output = []\n",
    "output_w_prompt = []\n",
    "for d in tqdm(data[:300]):\n",
    "    sent = d\n",
    "#     for i in range(12):\n",
    "#         print(i)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# generated = tokenizer.encode(f\"<BOS> MY FATHER MEETS THE CAT  <newline>  <newline>  <newline>  One cold rainy day when my father was a little boy , he met an old  <newline>  alley cat on his street . <endprompt> <EOS>\", return_tensors=\"pt\")\n",
    "    generated = tokenizer.encode(f'<BOS> {sent} <endprompt> <EOS>', return_tensors=\"pt\").cuda()\n",
    "#         print(generated)\n",
    "    sample_outputs = model.generate(generated, do_sample=True, top_k=50, max_length=350, top_p=0.95,\n",
    "            num_return_sequences=10, repetition_penalty=1.5, temperature=1.9, pad_token_id=tokenizer.eos_token_id)\n",
    "    # sample_outputs = model.generate(generated, max_length=50)\n",
    "    predicted_text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    sent = predicted_text.replace('\\n',' <newline> ')\n",
    "    output_w_prompt.append(sent)\n",
    "    output.append(sent[len(d):])\n",
    "\n",
    "# f = open(\"results/med_FairyDB_test_2.txt\", \"w\", encoding=\"utf-8\")\n",
    "f = open(\"results/medium_wp.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for out in output:\n",
    "    f.write(out + '\\n')\n",
    "f.close()\n",
    "f = open(\"results/medium_wp_2.txt\", \"w\", encoding=\"utf-8\")\n",
    "# f = open(\"results/med_prompt_FairyDB_test_2.txt\", \"w\", encoding=\"utf-8\")\n",
    "for out in output_w_prompt:\n",
    "    f.write(out + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
